import requests
from bs4 import BeautifulSoup
import csv
import re

# Configuration
url = "https://fr.wikipedia.org/wiki/Liste_des_anciennes_communes_de_l%27Is%C3%A8re"
output_file = "transferts_communes.csv"

def clean_text(text):
    """Nettoyer le texte des notes et r√©f√©rences"""
    return re.sub(r'\[.*?\]', '', text).strip()

def extract_communes(cell):
    """Extraire les communes d'une cellule TD"""
    text = re.sub(r'\([^)]*\)', '', cell.get_text())  # Supprimer les (1 commune)
    communes = [clean_text(c) for c in text.split(',')]
    return [c for c in communes if c]

print("‚è≥ T√©l√©chargement de la page...")
try:
    response = requests.get(url, timeout=10)
    response.raise_for_status()
    soup = BeautifulSoup(response.content, "html.parser")
except Exception as e:
    print(f"‚ùå Erreur de connexion: {e}")
    exit()

# Recherche du tableau cible
print("üîç Recherche du tableau des transferts...")
target_table = None


for table in soup.find_all("table", class_="wikitable"):
    headers = [th.get_text(" ", strip=True).lower() for th in table.find_all("th")]
    required_headers = [
        "d√©partement d'origine",
        "d√©partement de rattachement",
        "communes concern√©es"
    ]
    if all(any(h in header for header in headers) for h in required_headers):
        target_table = table
        break

if not target_table:
    print("‚ùå Tableau des transferts non trouv√©")
    exit()

# Extraction des donn√©es
print("üìä Extraction des donn√©es...")
data = []

for row in target_table.find_all("tr")[1:]:  # Skip header row
    cols = row.find_all("td")
    if len(cols) < 4:
        continue

    try:
        departement_origine = clean_text(cols[0].get_text())
        departement_rattachement = clean_text(cols[1].get_text())
        communes = extract_communes(cols[2])
        decision = clean_text(cols[3].get_text())

        # Extraire les ann√©es (ex: "1967", "1968", "1852")
        years = re.findall(r'\b(?:18|19|20)\d{2}\b', decision)
        unique_years = sorted(set(years))
        annees = ", ".join(unique_years) if unique_years else "Ann√©e inconnue"

        # Extraire une date compl√®te (ex: "5 mars 1971")
        date_match = re.search(r'\d{1,2}\s+\w+\s+\d{4}', decision)
        date = date_match.group(0) if date_match else "Date inconnue"

        data.append({
            "D√©partement d'origine": departement_origine,
            "D√©partement de rattachement": departement_rattachement,
            "Nombre de communes": len(communes),
            "Communes concern√©es": ", ".join(communes[:3]) + ("..." if len(communes) > 3 else ""),
            "Toutes les communes": ", ".join(communes),
            "Date": date,
            "Ann√©es de d√©cision": annees,
            "D√©cision compl√®te": decision
        })
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur traitement ligne: {e}")

# Export CSV
print(f"üíæ Sauvegarde dans {output_file}...")
try:
    with open(output_file, "w", newline="", encoding="utf-8") as csvfile:
        fieldnames = [
            "D√©partement d'origine",
            "D√©partement de rattachement",
            "Nombre de communes",
            "Communes concern√©es",
            "Toutes les communes",
            "Date",
            "Ann√©es de d√©cision",
            "D√©cision compl√®te"
        ]
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(data)

    print(f"‚úÖ {len(data)} transferts enregistr√©s avec succ√®s")
    print(f"üìã Exemple de donn√©es:")
    for i, item in enumerate(data):
        print(f"\nTransfert {i+1}:")
        print(f"- De: {item['D√©partement d\'origine']}")
        print(f"- Vers: {item['D√©partement de rattachement']}")
        print(f"- Communes: {item['Communes concern√©es']}")
        print(f"- Date: {item['Date']}")
        print(f"- Ann√©es: {item['Ann√©es de d√©cision']}")
except Exception as e:
    print(f"‚ùå Erreur lors de l'export CSV: {e}")
